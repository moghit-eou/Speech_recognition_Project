# ğŸ—£ï¸ Audio Spoken Digits Classification (MLP + Flask + Docker)

This project implements a **spoken digit classification system** using a **Multi-Layer Perceptron (MLP)** neural network trained on spectrograms of audio recordings.  
The model is deployed via **Flask** and containerized with **Docker**, and can be hosted on platforms like **Hugging Face Spaces**.

---

## ğŸ“Œ Project Overview

- **Goal:** Classify spoken digits (`0` to `9`) from audio recordings.
- **Feature Extraction:** Generate **spectrograms** from audio to obtain numerical representations.
- **Model Type:** Multi-Layer Perceptron (MLP) â€” *No CNN used*.
- **Frameworks:** `TensorFlow/Keras` for training, `Flask` for serving predictions.
- **Training Environment:** **Google Colab GPU** (NVIDIA Tesla T4).
- **Deployment:** Containerized with **Docker** and deployed on **Hugging Face Spaces**.
- **Model Size:** ~200 MB (handled using Git LFS).

---

## ğŸ“‚ Repository Structure
.
â”œâ”€â”€ Flask/ # Flask app with prediction endpoint & UI
â”‚ â”œâ”€â”€ static/ # CSS, JS, and static files
â”‚ â”œâ”€â”€ templates/ # HTML templates for web UI
â”‚ â”œâ”€â”€ app.py # Main Flask application
â”‚ â”œâ”€â”€ predict.py # Prediction logic
â”‚ â”œâ”€â”€ test.py # Local testing script
â”‚ â”œâ”€â”€ requirements.txt # Python dependencies
â”‚ â”œâ”€â”€ words.npz # Vocabulary/label encoder
â”‚ â”œâ”€â”€ recording.wav # Example input audio
â”‚ â”œâ”€â”€ last_model_e20_acc78_.keras # Trained MLP model
â”‚ â””â”€â”€ ...
â”œâ”€â”€ data/ # Dataset (if provided)
â”œâ”€â”€ models_last/ # Model storage
â”œâ”€â”€ audio_spectrogram.ipynb # Notebook for spectrogram generation
â”œâ”€â”€ model_evaluation.ipynb # Notebook for metrics & plots
â”œâ”€â”€ full_project.ipynb # Complete training + evaluation pipeline
â”œâ”€â”€ Dockerfile # Docker build file
â”œâ”€â”€ .gitattributes # Git LFS settings
â””â”€â”€ README.md # This file

